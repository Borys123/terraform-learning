terraform init
  - Downloads modules/plugins
  - Sets up state file

terraform plan
  - does not deploy anything. Read-only
  - allows users to review the action plan before execution
  - uses authentication credentials

terraform apply
  - updates the state file (state tracking mechanism) - terraform.tfstate

Default TF behaviors:
- executes code in .tf files
- initially, looks for providers in the registry, but can also locally
- refreshed prior to any modification
- acts as cache for res attrs

Terraform State - Resource tracking:
- json data
- terraform.tfstate locally

sensitive = true (default false)

Base types:
- string
- number
- boll

Complex types:
- list
- set
- map
- object
- tuple

Outputs:
- are shown on the shell after terraform apply

Common state commands:
terraform state list - list all resources tracked by state file
terraform state rm - delete a resource from state file
terraform state show - show details of a tracked resource

Modules can be downloaded/referenced from:
- Terraform Public Registry
- A Private registry
- Your Local System

Functions
User-defined functions are not allowed

Built-in functions:
- file
- max
- flatten

Terraform console (interactive cli)
max(5,3,1,4,5) -> 5
timestamp() -> UTC timestamp
join("_", ["acloud","guru"]) -> acloud_guru
contains(["acloud", "guru", 1, 2, 3], "guru") -> true
contains(["acloud", "guru", 1, 2, 3], "5") -> false

Terraform Type Constraints (Collections & Structurals)
- Type constraints control the type of variable values

Primitive - single type value (number, string, bool)
Complex - multiple types in a single variable (list, tuple, map, object)
Collection types allow multiple values of one primitive type to be grouped together list/map/set(type)
Structural types allow multiple values of different primitive types to be grouped together object/tuple/set(type)
Any - a placeholder for a primitive type yet to be decided

Terraform taint
- taints a resource, forcing it to be deleted and recreated
- modifies the state file, which causes the recreation workflow
- mind that tainting a resource may cause other resources to be modified
terraform taint RESOURCE_ADDRESS

Terraform import
- maps existing resources to Terraform using an ID
- ID is dependent on the underlying vendor
- importing the same reosource to multiple Terraform resources can cause unknown behavior, not recommended

terraform import resource_address ID

Terrafrom configuration block
- special configuration block for controlling Terraform's own behavior
- only allows constant values, named resources and variables not allowed
- configuring backend for storing state files
- specifying a required Terraform version
- Specifying a required Terraform Provider version and its requirements
- enable and test Terraform experimental features
- passing metadata to providers

Workspaces
- alternate state files within the same working directory
- starts with a single "default" workspace that cannot be deleted
- test using a parallel, distinct copy of infrastructure
- it can be modeled against branches in version control
- good for sharing resources, collaboration
- access to ${terraform.workspace}

terraform workspace new <WORKSPACE>
terraform workspace select <WORKSPACE>

Debugging Terraform

TF_LOG = env var for enabling verbose logging. By default sends to stderr
Can be set to: TRACE, DEBUG, INFO, WARN, ERROR
TRACE- most verbose and reliable
TF_LOG_PATH - log to file (path)
By default disabled

Sentinel
- provided with Enterprise version
- enforces policies on code
- own language - Sentinel language
- designed to be approached by non-programmers
- sandboxing - guardrails for automation (eg. stop dev user from deploying to prod)
- codifies security enfrorcement
- can be version controlled
- standardise testing and automation of security
- for enforcing CIS security standards on AWS accounts
- check to make sure only certain instances can be spun up
- ensure no security group allows port 22

Vault Provider

- secrets management software
- store sensitive data securely, provide short term credentials to users
- dynamically provisions credentials and rotates them
- encrypts sensitive data in transit and at rest, fine grained access control to secrets using ACLs
- usernames, passwords, db credentials, api tokens, tls certs
- prevent credentials sprawl
- centrally manage access to all secrets and integrate them easily with tf and cloud vendors

Benefits:
- Devs/users don't need long term creds on machines, less attack vectors
- Creds injected to terraform at runtime
- Fine-grained ACLs
- Main takeaway - both temp credentials, as well encryption of data at rest and transit

Terraform Registry
- a repository of publicly available Terraform providers and modules
- you can publish and share your own modules
- you can collaborate with other contributors to make changes to providers and modules
- can be directly referenced in Terraform code

Terraform Cloud Workspaces
- same as normal workspaces, but hosted in the cloud
- direcotires hosted in Terraform Cloud
- stores old version of state files
- mainains a record of all execution activity (auditing, investigating)
- all terrraform commands executed on "managed" Terraform Cloud VMs

Terraform Cloud Workspaces vs OSS Workspaces

OSS:
- stores alternate state files in the same working directory
- (terraform.tfstate.d keeps states of different workspaces)

Component                 Workspace                                                Cloud Workspace
TF Configuration           On disk                               Linked VC repository or uploaded by API/CLI calls
Variable Values      As .tfvars, CLI args, in shell env                       In workspace (TF Cloud)
TFState              On disk/remote backend                                   In workspace (TF Cloud)
Creds/Secrets        In shell env or entered at prompts               In workspace (TF Cloud), as sensitive values

TF Cloud (summary)
- Remote Terraform execution
- Workspace based org model
- VC integration (GitHub, Bitbucket etc)
- Remote state management and CLI integration
- Private Terraform Module registry
- Cost estimation (AWS, Azure, GCP) and Sentinel integration features
- Collaboration (API based worklflows, version control, trigger-based deployments)

Generic meta-arguments for provider: Profile, Region

Modules can be fetched with extensions: zip, tar.gz, tar.xz

Config under terraform_remote_state

terraform output <output_name>

Sources for modules: local path, tf registry, github, bitbucket, generic git/mercurial, http url, s3, gcs bucket, modules in package subdirectories

Can set "provider" inside a resource, when provider has an alias (eg. aws.frankfurt)

terraform logout, terraform login for both enterprise and cloud

TF_DATA_DIR - changes path where TF keeps its per-working-directort data (eg. remote backend config)

terraform replace

Count meta-argument accepts a whole number and creates that many instances of resource or module

Remote-exec provisioner uses SSH and WinRM

terraform force-unlock LOCK_ID

Standard (only stores) and Enhanced (stores and executes) backend. Local and Cloud are enhanced.

terraform apply --auto-approve

terraform console

terraform refresh - refreshes state

Terraform standard backend doesn't support remote management/operations

null_resource + local_exec

HCL and JSON

Current and desired state should be in the same state all the time? No

Features exclusive for TF Ent and Cloud Business: self-service infra, audit logging, SAML/SSO

Supported backend types: s3, terraform enterprise, artifactory, consul, terraform cloud, local

Supported OS: Widnows, Linux, MacOS, Solaris

Good functions: join, format, replace, NON EXISTENT: tostring

TF Enterprise = PostgreSQL backend

Plugins are in .terraform/plugins in init dir

How to make module valid for publishing: GitHub public repo, PCI/HIPPA compliant, repo named terraform-<PROIVDER>-<NAME>

Create provider dependency by: explicite use of a provider block, existence of any resource refering to a provider in current state, use of any resource belonging to a particular provider in resource/data block

Parallelism: 10

source = "git::https://example.com/my_test_module.git?ref=1.0.4"

Env vars in format TF_VAR_<SOMETHING>

TF Cloud supported providers: Azure DevOps, GH Enterprise, GH, Bitbucket Cloud, !NOT! CVS VC

Install modules: terraform init or terraform get

TF install without installer or upgrades = air-gapped

~> 1.2.0 means 1.2.X

zipmap(["a", "b"], [1, 2]) = {"a" = 1 "b" = 2}

Terraform is an immutable, declarative, IaC provisioning language based or HCL or optionally JSON

lookup ({a = "hello", b="goodbye",}, "c", "what?") = what?

When using providers that require retrieval of data, it happens during plan

State in OSS resides in terraform.tfstate.d

When commiting, ignore terraform.tfstate and terraform.tfvars

Features ONLY in Enterprise: Locally hosted installation, private network connectivity. NOT clustering, audit logs, saml/sso

Before importing, update the config file to include new resources

Downside to using vault (eg. reading secrets from it): secrets are persisted to tf state and plans

State file: storing state remotely is more secure, tf state can contain sensitive data, protect it, locally it's plain txt, tf cloud always encrypts state at rest

Configure backend not in code: command line key/value pairs, interactively on cli, use -backend-config=PATH-TO-FILE

Benefits of modules published via tf registry: auto-generated docs, browsing version history, show examples and readmes, support versioning, NOT support from any code repo
